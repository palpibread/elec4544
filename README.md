# elec4544
This reposiry is for HKU elec4544. We test the idea of adding more channels with group convolution. Here is the abstract.
It has been a consensus that group convolution could reduce the computational cost but no direct research could show that such an operator may increase or deteriorate the image classification accuracy. Inspired by the ResNeXt\cite{xie2017aggregated}, we focused on the relationship between wider channels and more groups in the modification of classic networks, \ie, AlexNet\cite{krizhevsky2012imagenet} and VGG-16\cite{simonyan2014very}. It turns out that with our modification, the top-1 classification accuracy of AlexNet\cite{krizhevsky2012imagenet} increased by *2.22%* and *1.88%* on Flowers\cite{flower} and MiniImageNet respectively, and for VGG-16 our modified models achieved *2.06\%*, \textbf{1.48\%} and \textbf{3.40\%} more validation accuracy on CIFAR-10\cite{cifar}, Flowers\cite{flower} and MiniImageNet respectively. We also designed the ablation study to illustrate the necessity of adopting group convolution when attempting to enlarge the VGG-16 network architecture. Our experiment proves that group convolution is not only a way to reduce the computational cost but also a way to avoid over-fitting, accelerate the training process, and enhance the generalization capability.
